{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "from ibm_watsonx_ai.foundation_models import Model\nimport os,getpass\n\n# In this step, you will be asked to provide an api key with which an access token can be created that is required to authenticate with the API.\n# You can create such an api key here: https://cloud.ibm.com/iam/apikeys\n\ndef get_credentials():\n    return {\n        \"url\" : \"https://us-south.ml.cloud.ibm.com\",\n        \"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n    }\n\nparameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 100,\n    \"stop_sequences\": [\"\\n\\n\"],\n    \"repetition_penalty\": 1\n}\n\nmodel = Model(\n    model_id = \"meta-llama/llama-3-8b-instruct\",\n    params = parameters,\n    credentials = get_credentials(),\n    project_id = os.getenv('PROJECT_ID')\n    )\n\nprompt_input = \"\"\"Answer the following question using only information from the article. If there is no good answer in the article, say \"I don't know\".\n\nArticle: \n###\nTomatoes are one of the most popular plants for vegetable gardens. Tip for success: If you select varieties that are resistant to disease and pests, growing tomatoes can be quite easy. For experienced gardeners looking for a challenge, there are endless heirloom and specialty varieties to cultivate. Tomato plants come in a range of sizes. There are varieties that stay very small, less than 12 inches, and grow well in a pot or hanging basket on a balcony or patio. Some grow into bushes that are a few feet high and wide, and can be grown is larger containers. Other varieties grow into huge bushes that are several feet wide and high in a planter or garden bed. Still other varieties grow as long vines, six feet or more, and love to climb trellises. Tomato plants do best in full sun. You need to water tomatoes deeply and often. Using mulch prevents soil-borne disease from splashing up onto the fruit when you water. Pruning suckers and even pinching the tips will encourage the plant to put all its energy into producing fruit.\n###\n\nQuestion: Is growing tomatoes easy?\nAnswer: Yes, if you select varieties that are resistant to disease and pests.\n\nQuestion: What varieties of tomatoes are there?\nAnswer: There are endless heirloom and specialty varieties.\n\nQuestion: Why should you use mulch when growing tomatoes?\nAnswer: \"\"\"\n\nprint(\"Submitting generation request...\")\ngenerated_response = model.generate_text(prompt=prompt_input, guardrails=True)\nprint(generated_response)\n\n![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Prompt Notebook with Chat - Prompt Lab Notebook v1.1.0\nThis notebook contains steps and code to demonstrate inferencing of prompts\ngenerated in Prompt Lab in watsonx.ai with a chat format. It introduces Python API commands\nfor authentication using API key and prompt inferencing using WML API.\n\n**Note:** Notebook code generated using Prompt Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.10.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Defining parameters of the Model object\n* Using the Model object to generate response using the defined model id, parameters and the prompt input\n\n# Setup"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n"
        },
        {
            "cell_type": "raw",
            "metadata": {},
            "source": "# Inferencing\nThis cell demonstrated how we can use the model object as well as the created access token\nto pair it with parameters and input string to obtain\nthe response from the the selected foundation model.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "model_id = \"meta-llama/llama-3-70b-instruct\"\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "parameters = {\n    \"decoding_method\": \"greedy\",\n    \"max_new_tokens\": 900,\n    \"repetition_penalty\": 1\n}"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Defining the Model object\nWe need to define the Model object using the properties we defined so far:\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from ibm_watsonx_ai.foundation_models import Model\n\nmodel = Model(\n\tmodel_id = model_id,\n\tparams = parameters,\n\tcredentials = get_credentials(),\n\tproject_id = project_id,\n\tspace_id = space_id\n\t)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Defining the inferencing input for chat\nFoundation models supporting chat accept a system prompt that instructs the model on how to conduct the dialog. They also accept previous questions and answers to give additional context when inferencing. Each model has it's own string format for constructing the input.\n\nLet us provide the input we got from the Prompt Lab and format it for the selected model:\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "prompt_input = \"\"\"<|start_header_id|>system<|end_header_id|>\n\nYou always answer the questions with markdown formatting using GitHub syntax. The markdown formatting you support: headings, bold, italic, links, tables, lists, code blocks, and blockquotes. You must omit that you answer the questions with markdown.\n\nAny HTML tags must be wrapped in block quotes, for example ```<html>```. You will be penalized for not rendering code in block quotes.\n\nWhen returning code blocks, specify language.\n\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. \nYour answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\nShow review titles for Cognos Analytics from TR<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n### Review Titles for Cognos Analytics from TrustRadius\n\n| **Review Title** |\n| --- |\n| **Cognos Analytics - A Powerful Tool for Data Analysis** |\n| **A Game Changer for Business Intelligence** |\n| **Cognos Analytics: A Robust and Scalable BI Solution** |\n| **Easy to Use, Difficult to Master** |\n| **Cognos Analytics: A Solid Choice for Enterprise BI** |\n| **A Steep Learning Curve, but Worth the Effort** |\n| **Cognos Analytics: A Comprehensive BI Platform** |\n| **Good for Large Enterprises, but Not for Small Businesses** |\n| **Cognos Analytics: A Powerful, Yet Complex Tool** |\n| **A Good Choice for Those Familiar with IBM Products** |\n\nNote: These review titles are fictional and for demonstration purposes only. They do not reflect actual reviews from TrustRadius.\"\"\"\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Execution\nLet us now use the defined Model object, pair it with the input, and generate the response to your question:\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "question = input(\"Question: Count the reviews for Cognos Analytics\")\nformattedQuestion = f\"\"\"<|begin_of_text|><|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n\"\"\"\nprompt = f\"\"\"{prompt_input}{formattedQuestion}\"\"\"\ngenerated_response = model.generate_text(prompt=prompt, guardrails=False)\nprint(f\"AI: {generated_response}\")\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for Watson Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "Trust Radius"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}